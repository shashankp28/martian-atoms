{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.signal import savgol_filter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>split</th>\n",
       "      <th>derivatized</th>\n",
       "      <th>features_path</th>\n",
       "      <th>features_md5_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0000</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train_features/S0000.csv</td>\n",
       "      <td>52ec6d6f8372500ab4e069b5fbdae6f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0001</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train_features/S0001.csv</td>\n",
       "      <td>348f90baed8a8189bf0d4c7b9ed9f965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0002</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train_features/S0002.csv</td>\n",
       "      <td>4686ad9bc3716966f63b6ff83d1d8324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0003</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train_features/S0003.csv</td>\n",
       "      <td>de6b53605c5887967dc3661a3a711c2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train_features/S0004.csv</td>\n",
       "      <td>fbfd90092d10d15a5d6919327ddde2ab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id  split  derivatized             features_path  \\\n",
       "0     S0000  train          NaN  train_features/S0000.csv   \n",
       "1     S0001  train          NaN  train_features/S0001.csv   \n",
       "2     S0002  train          1.0  train_features/S0002.csv   \n",
       "3     S0003  train          NaN  train_features/S0003.csv   \n",
       "4     S0004  train          NaN  train_features/S0004.csv   \n",
       "\n",
       "                  features_md5_hash  \n",
       "0  52ec6d6f8372500ab4e069b5fbdae6f9  \n",
       "1  348f90baed8a8189bf0d4c7b9ed9f965  \n",
       "2  4686ad9bc3716966f63b6ff83d1d8324  \n",
       "3  de6b53605c5887967dc3661a3a711c2b  \n",
       "4  fbfd90092d10d15a5d6919327ddde2ab  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('metadata.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "all_ids = list(metadata.sample_id)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALl labels: ['aromatic', 'hydrocarbon', 'carboxylic_acid', 'nitrogen_bearing_compound', 'chlorine_bearing_compound', 'sulfur_bearing_compound', 'alcohol', 'other_oxygen_bearing_compound', 'mineral']\n",
      "Maximum mass: 649.96228\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def metadata_parser(metadata):\n",
    "    train_dict = {}\n",
    "    val_dict = {}\n",
    "    for row in metadata.iterrows():\n",
    "        if row[1].split == 'train':\n",
    "            train_dict[row[1].sample_id] = row[1].features_path\n",
    "        else:\n",
    "            val_dict[row[1].sample_id] = row[1].features_path\n",
    "    return train_dict, val_dict\n",
    "\n",
    "def train_label_parser(train_labels):\n",
    "    train_labels_dict = {}\n",
    "    for row in train_labels.iterrows():\n",
    "        row_list = list(row[1])\n",
    "        train_labels_dict[row_list[0]] = row_list[1:]\n",
    "    columns = list(train_labels.columns)\n",
    "    return train_labels_dict, columns[1:]\n",
    "\n",
    "def get_ids_per_class():\n",
    "    ids_per_class = {}\n",
    "    for class_name in labels:\n",
    "        index = labels.index(class_name)\n",
    "        ids = []\n",
    "        for key, value in train_labels_dict.items():\n",
    "            if value[index] == 1:\n",
    "                ids.append(key)\n",
    "        ids_per_class[class_name] = ids\n",
    "    return ids_per_class\n",
    "\n",
    "def find_absolute_maximum_mass():\n",
    "    print(\"Finding absolute maximum mass\")\n",
    "    pb = tqdm(total=len(all_ids))\n",
    "    absolute_max = 0\n",
    "    for key, value in all_paths.items():\n",
    "        pb.update(1)\n",
    "        data = pd.read_csv(value)\n",
    "        data.sort_values('mass')\n",
    "        max_mass = data['mass'].max()\n",
    "        absolute_max = max(absolute_max, max_mass)\n",
    "    return absolute_max\n",
    "\n",
    "def data_parser(id):\n",
    "    path = all_paths[id]\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.sort_values('mass')\n",
    "    labels = list(data.columns)\n",
    "    data_json = {\n",
    "        'time': np.array(data.time),\n",
    "        'mass': np.array(data.mass),\n",
    "        'intensity': np.array(data.intensity),\n",
    "    }\n",
    "    return data_json\n",
    "\n",
    "def descretize(data, mass_range, interval):\n",
    "    mass = data['mass'].copy()\n",
    "    intensity = data['intensity'].copy()\n",
    "    num_elements = int(mass_range / interval) + 1\n",
    "    intensity_desc = np.zeros(num_elements)\n",
    "    for i in range(num_elements):\n",
    "        mass_start = i * interval\n",
    "        mass_end = (i + 1) * interval\n",
    "        mask = (mass >= mass_start) & (mass < mass_end)\n",
    "        if np.any(mask):\n",
    "            intensity_desc[i] = np.max(intensity[mask])\n",
    "    return intensity_desc\n",
    "\n",
    "def intensity_vs_mass_plotter(sample_id, discretized=False, mass_range=650, interval=0.5):\n",
    "    data = data_parser(sample_id)\n",
    "    if discretized:\n",
    "        data['intensity'] = descretize(data, mass_range, interval)\n",
    "        data['mass'] = np.array([i*interval for i in range(len(data['intensity']))])\n",
    "    fig, axs = plt.subplots(figsize=(20, 10))\n",
    "    axs.set_xlim(0, 650)\n",
    "    axs.plot(data['mass'], data['intensity'])\n",
    "\n",
    "def abosulte_average_deviation():\n",
    "    deviations = 0\n",
    "    count = 0\n",
    "    for sample_id in tqdm(all_ids):\n",
    "        data = data_parser(sample_id)\n",
    "        mass = data['mass']\n",
    "        for i in range(len(mass) - 1):\n",
    "            deviations += np.abs(mass[i+1] - mass[i])\n",
    "            count += 1\n",
    "    return deviations, count\n",
    "\n",
    "def descritize_dataset(dataset_paths, max_mass, step, file_name):\n",
    "    with open(file_name, 'w+') as f:\n",
    "        columns = ['sample_id']\n",
    "        num_elements = int(max_mass / step) + 1\n",
    "        for i in range(num_elements):\n",
    "            columns.append(f'I{i}')\n",
    "        f.write(','.join(columns) + '\\n')\n",
    "        for key, value in tqdm(dataset_paths.items()):\n",
    "            data = data_parser(key)\n",
    "            intensity_desc = descretize(data, max_mass, step)\n",
    "            max_intensity = np.max(intensity_desc)\n",
    "            values = key+','+','.join([str(i/max_intensity) for i in intensity_desc]) + '\\n'\n",
    "            f.write(values)\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "train_path, val_path = metadata_parser(metadata)\n",
    "train_labels_dict, labels = train_label_parser(train_labels)\n",
    "all_paths = {**train_path, **val_path}\n",
    "ids_per_class = get_ids_per_class()\n",
    "# absolute_maximum_mass = find_absolute_maximum_mass()   Already found\n",
    "# absolute_average_deviation, total_count = abosulte_average_deviation() Already Done\n",
    "absolute_maximum_mass = 649.96228 \n",
    "absolute_mean_diff = 544345.6024272853/591544015\n",
    "# descritize_dataset(train_path, 650, 0.5, \"train_descrete.csv\") Already Done\n",
    "# descritize_dataset(val_path, 650, 0.5, \"val_descrete.csv\") Already Done\n",
    "print(\"Absolute maximum mass: \", absolute_maximum_mass)\n",
    "print(\"Absolute mean difference: \", absolute_mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
